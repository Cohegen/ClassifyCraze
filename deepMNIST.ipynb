{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documetation:MNIST Handwritten Digit Classification with Deep MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Project Overview\n",
    "This project involves building,training\n",
    "and evaluating a Deep Multi-Layer \n",
    "Perceptron(MLP) to classify\n",
    "handwritten digits from the MNIST \n",
    "dataset.The goal is to achieve over 98%\n",
    "precision on the test set while\n",
    "incorporating the best practices, such as\n",
    "saving checkppoints,using early\n",
    "stopping,and visualizing learning \n",
    "curves with TensorBoard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Problem Statement:\n",
    "The MNIST dataset consists of 28x28 \n",
    "grayscale images of handwritten digits\n",
    "(0-9).The task is to develop a machine \n",
    "learning model that can classify each \n",
    "image into the correct digit category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Dataset Description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: The MNIST dataset is available in the\n",
    "\n",
    "tensorflow.keras.datasets module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Set: 60,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set:10,000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:Each images is a 28x28 \n",
    "matrix of pixel values(grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels:Each image corresponds to a digit from 0 to 9(10 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Steps:\n",
    "\n",
    "1.Normalize pixel values to the range [0,1]\n",
    "\n",
    "2.Convert the labels to one-hot encoding for multi-class classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Model Architecture\n",
    "\n",
    "The MLP model includes:\n",
    "\n",
    "\n",
    "1.Input layer:Flatten the 28x28 input images into a vector of size 784.\n",
    "\n",
    "\n",
    "2.Hidden Layers:\n",
    "   \n",
    "\n",
    "   Dense layers with ReLU activation functions.\n",
    "\n",
    "   Dropout layers for regularization(prevent overfitting).\n",
    "\n",
    "\n",
    "\n",
    "3.Output Layer: Dense layer with 10 units and softmax activation to predict class probabilities.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Model Summary:\n",
    "\n",
    "| Layer Type   | Number of Neurons | Activation | Dropout |\n",
    "|--------------|--------------------|------------|---------|\n",
    "| Input Layer  | 784                | -          | -       |\n",
    "| Dense Layer  | 512                | ReLU       | 0.3     |\n",
    "| Dense Layer  | 256                | ReLU       | 0.3     |\n",
    "| Dense Layer  | 128                | ReLU       | 0.3     |\n",
    "| Output Layer | 10                 | Softmax    | -       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Training Process\n",
    "\n",
    "Hyperparameters:\n",
    "\n",
    "Optimizer: Adam (adaptive learning rate optimization).\n",
    "\n",
    "Loss Function: Categorical Cross-Entropy.\n",
    "\n",
    "Metrics: Accuracy.\n",
    "\n",
    "Batch Size: 128.\n",
    "\n",
    "Epochs: Up to 50 (with early stopping)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks:\n",
    "\n",
    "Model Checkpoint: Saves the model weights with the highest validation accuracy.\n",
    "\n",
    "Early Stopping: Stops training if validation loss doesn't improve for 5 consecutive epochs.\n",
    "\n",
    "TensorBoard: Logs training and validation metrics for visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Implementation\n",
    "\n",
    "Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and preproccess the mnist dataset\n",
    "(x_train,y_train) ,(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP 840 G3\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Define the deep MLP model\n",
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(10,activation=\"softmax\")\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Set Up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define callbacks\n",
    "log_dir = os.path.join(\"logs\",datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_model.h5.keras\",save_best_only=True,monitor=\"val_accuracy\"),\n",
    "    EarlyStopping(monitor=\"val_loss\",patience=5,restore_best_weights=True),\n",
    "    TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.7710 - loss: 0.7126 - val_accuracy: 0.9608 - val_loss: 0.1293\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9506 - loss: 0.1684 - val_accuracy: 0.9714 - val_loss: 0.1005\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9655 - loss: 0.1192 - val_accuracy: 0.9729 - val_loss: 0.0937\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9733 - loss: 0.0883 - val_accuracy: 0.9753 - val_loss: 0.0832\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9755 - loss: 0.0778 - val_accuracy: 0.9750 - val_loss: 0.0876\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9808 - loss: 0.0625 - val_accuracy: 0.9771 - val_loss: 0.0807\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9817 - loss: 0.0601 - val_accuracy: 0.9768 - val_loss: 0.0787\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9834 - loss: 0.0536 - val_accuracy: 0.9749 - val_loss: 0.0894\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9843 - loss: 0.0494 - val_accuracy: 0.9782 - val_loss: 0.0807\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9854 - loss: 0.0443 - val_accuracy: 0.9780 - val_loss: 0.0847\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9876 - loss: 0.0394 - val_accuracy: 0.9785 - val_loss: 0.0874\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9869 - loss: 0.0422 - val_accuracy: 0.9788 - val_loss: 0.0836\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs = 50,\n",
    "    batch_size = 128,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy97.91%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test,verbose=0)\n",
    "print(f\"Test Accuracy {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#Save final model\n",
    "model.save(\"final_mlp_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Results\n",
    "\n",
    "Expected Test Accuracy: ≥98%.\n",
    "\n",
    "Best Model: Saved as best_model.h5.\n",
    "\n",
    "Training Metrics: Available through TensorBoard (tensorboard --logdir logs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Future Improvements\n",
    "\n",
    "Experiment with advanced architectures, such as Convolutional Neural Networks (CNNs), which are better suited for image data.\n",
    "\n",
    "Implement data augmentation to artificially expand the training dataset.\n",
    "\n",
    "Optimize hyperparameters using techniques like grid search or Bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Project Files\n",
    "\n",
    "final_mlp_model.h5: The final trained model.\n",
    "\n",
    "best_model.h5: The best-performing model during training.\n",
    "\n",
    "TensorBoard logs: Stored in the logs/ directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
